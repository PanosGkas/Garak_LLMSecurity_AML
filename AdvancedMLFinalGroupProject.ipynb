{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PanosGkas/Garak_LLMSecurity_AML/blob/main/AdvancedMLFinalGroupProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Advanced Machine Learning - Final Project\n",
        "\n",
        "\n",
        "| **Members**          | **MSc** | **AEM** |\n",
        "|----------------------|:-------:|:-------:|\n",
        "| Katsaki Sofia        |    AI   |   165   |\n",
        "| Boulionis Athanasios |    AI   |   189   |\n",
        "| Gkasios Panagiotis   |    AI   |   173   |\n"
      ],
      "metadata": {
        "id": "ghBXNwH8uuA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import subprocess"
      ],
      "metadata": {
        "id": "rp8hu5xg1eHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHbAnx3GxtD6",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title Install Garak(Nvidia) → LLM vulnerability scanner\n",
        "\n",
        "!pip install garak"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Because some models may require access, you must connect to the hugging face\n",
        "\n",
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "V7pf4JAz1hkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title check For All Available Probes\n",
        "\n",
        "!python -m garak --list_probes"
      ],
      "metadata": {
        "id": "XjFolUp-vtEB",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "v2b6adqbR2He"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Base Models Ready To Use - Hugging Face\n",
        "\n",
        "# it:instruct  hf:hugging face #\n",
        "\n",
        "deepseek_models = [\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\", \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\", \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\", \"deepseek-ai/DeepSeek-V2-Lite\"]\n",
        "google_gemma_models = [\"google/gemma-2-2b-it\", \"google/gemma-3-1b-it\", \"google/gemma-7b\"]\n",
        "qwen_models = [\"Qwen/Qwen3-0.6B\", \"Qwen/Qwen3-0.6B-Base\"]\n",
        "microsoft_phi_models = [\"microsoft/Phi-4-mini-instruct\", \"microsoft/phi-2\", \"microsoft/Phi-3-mini-128k-instruct\", \"microsoft/Phi-3-mini-4k-instruct\", \"microsoft/phi-4\"]\n",
        "openai_models = [\"openai-community/gpt2\", \"openai-community/gpt2-xl\", \"openai-community/gpt2-large\"]\n",
        "eleuther_models = [\"EleutherAI/gpt-neo-1.3B\"]\n",
        "\n",
        "# microsoft_bitnet_models = [\"microsoft/bitnet-b1.58-2B-4T\", \"microsoft/bitnet-b1.58-2B-4T-gguf\", \"microsoft/bitnet-b1.58-2B-4T-bf16\"]\n",
        "# meta_llama_models = [\"meta-llama/Llama-3.2-3B-Instruct\", \"meta-llama/Llama-3.1-8B-Instruct\", \"meta-llama/Llama-2-7b-hf\", \"meta-llama/Llama-2-7b\"]\n",
        "# mistral_models = [\"mistralai/Mistral-7B-v0.1\", \"mistralai/Mistral-7B-Instruct-v0.2\", \"mistralai/Mistral-7B-Instruct-v0.3\", \"mistralai/Mixtral-8x7B-Instruct-v0.1\", \"mistralai/Mistral-Small-24B-Instruct-2501\"]"
      ],
      "metadata": {
        "id": "6bSskpqQ38Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The following models were taken from the aforementioned set:\n",
        "\n",
        "*   deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
        "*   google/gemma-2-2b-it\n",
        "*   Qwen/Qwen3-0.6B\n",
        "*   microsoft/Phi-4-mini-instruct\n",
        "*   openai-community/gpt2  \n",
        "*   EleutherAI/gpt-neo-1.3B\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_FOA2tclKrSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fine-Tuned Models Ready To Use - Hugging Face\n",
        "\n",
        "deepseek_ft_models = [\"agentica-org/DeepScaleR-1.5B-Preview\"]\n",
        "google_gemma_ft_models = [\"minchyeom/ThinkerGemma-2\",\"martimfasantos/gemma-2-2b-it-mt-sft-full_new\",\"Estwld/GENOME-gemma-2b-it\",\"zli12321/prometheus2-2B\"]\n",
        "qwen_ft_models = [\"unsloth/Qwen3-0.6B\", \"suayptalha/Arcana-Qwen3-2.4B-A0.6B\", \"Qwen/Qwen3-0.6B-Base\"] #suayptalha/Arcana-Qwen3-2.4B-A0.6B\n",
        "microsoft_ft_models = [\"unsloth/Phi-4-mini-instruct\",\"Jarrodbarnes/Cortex-1-mini\",\"lunahr/Phi-4-mini-instruct-abliterated\",\"huihui-ai/Phi-4-mini-instruct-abliterated\",\"ntnu-smil/phi-4-mini-prompt1\"]\n",
        "openai_ft_models = [\"diffusionfamily/diffugpt-s\", \"phonemetransformers/GPT2-85M-BPE-TXT\", \"akari000/gpt-2-artificial-vss-40\",\"manupande21/GPT2_PMC\", \"DigRabbit6666/protein-gpt2\"]\n",
        "eleuther_ft_models = [\"KimByeongSu/gpt-neo-1.3B_LAMA_TREx_finetuning_aeda\",\"sirine21/gptneo-finetuned-seo\", \"KimByeongSu/gpt-neo-1.3B_LAMA_TREx_finetuning_eda\"]\n"
      ],
      "metadata": {
        "id": "VkT2gID6QAFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The following Fine-Tuned models were taken from the aforementioned set:\n",
        "\n",
        "*   agentica-org/DeepScaleR-1.5B-Preview\n",
        "*   minchyeom/ThinkerGemma-2\n",
        "*   unsloth/Qwen3-0.6B\n",
        "*   huihui-ai/Phi-4-mini-instruct-abliterated\n",
        "*   akari000/gpt-2-artificial-vss-4\n",
        "*   KimByeongSu/gpt-neo-1.3B_LAMA_TREx_finetuning_aeda\n",
        "*   sirine21/gptneo-finetuned-seo\n",
        "\n",
        "\n",
        "*AEDA = an easier data augmentation*\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FL4ljXZkRKhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title List of Probes\n",
        "\n",
        "probes_list = [\"continuation\", \"dan\", \"encoding\", \"glitch\", \"goodside\", \"leakreplay\", \"lmrc\", \"malwaregen\", \"misleading\", \"promptinject\", \"realtoxicityprompts\", \"snowball\", \"xss\"]\n"
      ],
      "metadata": {
        "id": "y10xPlq2Pcls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Indicative Execution Sample\n",
        "\n",
        "!python -m garak --model_type huggingface --model_name google/gemma-3-1b-it --probes test.Blank"
      ],
      "metadata": {
        "id": "VLkoZq45OuSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run (Automated) Vulnerability Scan-Test : Parameters → [ Model_Name, Probes ]\n",
        "\n",
        "for probe in probes_list:\n",
        "  com = f\"python -m garak --model_type huggingface --model_name {google_gemma_models[0]} --probes {probe}\"\n",
        "  res = subprocess.run(com, shell=True, text=True, stdout=subprocess.PIPE)\n",
        "  print(res.stdout)"
      ],
      "metadata": {
        "id": "0w7xu8GfHiGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save (Report/Hitlog) Results after Vulnerability Scan\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Path of the folder to be saved\n",
        "folder_path = '/root/.local/share/garak/garak_runs'\n",
        "\n",
        "# Create zip and download without saving in Colab\n",
        "!zip -r -j /tmp/{folder_path.split('/')[-1]}.zip {folder_path}/*\n",
        "\n",
        "# Download zip folder with results\n",
        "files.download(f'/tmp/{folder_path.split(\"/\")[-1]}.zip')\n"
      ],
      "metadata": {
        "id": "5jT7ZtwtpskV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning the folder from the path\n",
        "\n",
        "%cd /root/.local/share/garak/garak_runs\n",
        "%ls\n",
        "%rm *.*"
      ],
      "metadata": {
        "id": "rFS8B_nTNBD8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}